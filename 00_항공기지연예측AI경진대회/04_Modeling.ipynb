{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9788dd3a",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9241c592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f7e03b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data load 함수\n",
    "def load_data() :\n",
    "    df_train = pd.read_csv('train.csv')\n",
    "    df_test = pd.read_csv('test.csv')\n",
    "    df_sub = pd.read_csv('sample_submission.csv')\n",
    "    return df_train, df_test, df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85230320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 함수 \n",
    "def preprocess_data(df_train, df_test) : \n",
    "    \n",
    "    # train 데이터 타겟값을 0, 1로 변경 \n",
    "    df_train['Delay'].replace('Not_Delayed', 0, inplace=True)\n",
    "    df_train['Delay'].replace('Delayed', 1, inplace=True)\n",
    "    \n",
    "    # 타겟값이 null이 아닌 데이터만 추출\n",
    "    df_train = df_train[df_train['Delay'].notnull()]\n",
    "    \n",
    "    # train, test 데이터를 합쳐 전처리 \n",
    "    df = pd.concat([df_train, df_test])\n",
    "    \n",
    "    # 불필요한 피쳐 drop\n",
    "    df.drop(['Cancelled', 'Diverted', 'Origin_Airport_ID', 'Destination_Airport_ID',\n",
    "            'Carrier_ID(DOT)'], axis=1, inplace=True)\n",
    "    \n",
    "    # 출발/도착 시간 (hour) 컬럼 생성\n",
    "    df['Estimated_Departure_Time_Hour'] = df['Estimated_Departure_Time'].astype(str).apply(lambda x : x.split('.')[0].zfill(4)[:-2])\n",
    "    df['Estimated_Departure_Time_Hour'] = df['Estimated_Departure_Time_Hour'].replace('0n', np.nan).astype(float)\n",
    "    df['Estimated_Arrival_Time_Hour'] = df['Estimated_Arrival_Time'].astype(str).apply(lambda x : x.split('.')[0].zfill(4)[:-2])\n",
    "    df['Estimated_Arrival_Time_Hour'] = df['Estimated_Arrival_Time_Hour'].replace('0n', np.nan).astype(float)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97306ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 컬럼별 지연율(파생컬럼) 생성 + 라벨 인코딩 함수 \n",
    "\n",
    "def df_merge_agg(df) :\n",
    "    # Month agg 연산\n",
    "    month_grp = df.groupby('Month')\n",
    "    month_dict = {\n",
    "        'Month' : ['count'],\n",
    "        'Delay' : ['sum']\n",
    "    }\n",
    "    month_agg = month_grp.agg(month_dict)\n",
    "    month_agg.columns = ['count', 'sum']\n",
    "    month_agg['month_delay_ratio'] = month_agg['sum'] / month_agg['count']\n",
    "    month_agg = month_agg['month_delay_ratio'].reset_index()\n",
    "    \n",
    "    # Day agg 연산\n",
    "    day_grp = df.groupby('Day_of_Month')\n",
    "    day_dict = {\n",
    "        'Day_of_Month' : ['count'],\n",
    "        'Delay' : ['sum']\n",
    "    }\n",
    "    day_agg = day_grp.agg(day_dict)\n",
    "    day_agg.columns = ['count', 'sum']\n",
    "    day_agg['day_delay_ratio'] = day_agg['sum'] / day_agg['count']\n",
    "    day_agg = day_agg['day_delay_ratio'].reset_index()\n",
    "    \n",
    "    # 출발 시간 agg 연산\n",
    "    depart_hour_grp = df.groupby('Estimated_Departure_Time_Hour')\n",
    "    depart_hour_dict = {\n",
    "        'Estimated_Departure_Time_Hour' : ['count'],\n",
    "        'Delay' : ['sum']\n",
    "    }\n",
    "    depart_hour_agg = depart_hour_grp.agg(depart_hour_dict)\n",
    "    depart_hour_agg.columns = ['count', 'sum']\n",
    "    depart_hour_agg['depart_hour_ratio'] = depart_hour_agg['sum'] / depart_hour_agg['count']\n",
    "    depart_hour_agg = depart_hour_agg['depart_hour_ratio'].reset_index()\n",
    "    \n",
    "    # 도착 시간 agg 연산\n",
    "    arrival_hour_grp = df.groupby('Estimated_Arrival_Time_Hour')\n",
    "    arrival_hour_dict = {\n",
    "        'Estimated_Arrival_Time_Hour' : ['count'],\n",
    "        'Delay' : ['sum']\n",
    "    }\n",
    "    arrival_hour_agg = arrival_hour_grp.agg(arrival_hour_dict)\n",
    "    arrival_hour_agg.columns = ['count', 'sum']\n",
    "    arrival_hour_agg['arrival_hour_ratio'] = arrival_hour_agg['sum'] / arrival_hour_agg['count']\n",
    "    arrival_hour_agg = arrival_hour_agg['arrival_hour_ratio'].reset_index()\n",
    "    \n",
    "    # 출발 공항 agg 연산\n",
    "    origin_airport_grp = df.groupby('Origin_Airport')\n",
    "    origin_airport_dict = {\n",
    "        'Origin_Airport' : ['count'],\n",
    "        'Delay' : ['sum']\n",
    "    }\n",
    "    origin_airport_agg = origin_airport_grp.agg(origin_airport_dict)\n",
    "    origin_airport_agg.columns = ['count', 'sum']\n",
    "    origin_airport_agg['origin_airport_delay_ratio'] = origin_airport_agg['sum'] / origin_airport_agg['count']\n",
    "    origin_airport_agg = origin_airport_agg['origin_airport_delay_ratio'].reset_index()\n",
    "    \n",
    "    # 출발 주 agg 연산\n",
    "    origin_state_grp = df.groupby('Origin_State')\n",
    "    origin_state_dict = {\n",
    "        'Origin_State' : ['count'],\n",
    "        'Delay' : ['sum']\n",
    "    }\n",
    "    origin_state_agg = origin_state_grp.agg(origin_state_dict)\n",
    "    origin_state_agg.columns = ['count', 'sum']\n",
    "    origin_state_agg['origin_state_delay_ratio'] = origin_state_agg['sum'] / origin_state_agg['count']\n",
    "    origin_state_agg = origin_state_agg['origin_state_delay_ratio'].reset_index()\n",
    "    \n",
    "    # 도착 공항 agg 연산\n",
    "    dest_airport_grp = df.groupby('Destination_Airport')\n",
    "    dest_airport_dict = {\n",
    "        'Destination_Airport' : ['count'],\n",
    "        'Delay' : ['sum']\n",
    "    }\n",
    "    dest_airport_agg = dest_airport_grp.agg(dest_airport_dict)\n",
    "    dest_airport_agg.columns = ['count', 'sum']\n",
    "    dest_airport_agg['dest_airport_delay_ratio'] = dest_airport_agg['sum'] / dest_airport_agg['count']\n",
    "    dest_airport_agg = dest_airport_agg['dest_airport_delay_ratio'].reset_index()\n",
    "    \n",
    "    # 도착 주 agg 연산\n",
    "    dest_state_grp = df.groupby('Destination_State')\n",
    "    dest_state_dict = {\n",
    "        'Destination_State' : ['count'],\n",
    "        'Delay' : ['sum']\n",
    "    }\n",
    "    dest_state_agg = dest_state_grp.agg(dest_state_dict)\n",
    "    dest_state_agg.columns = ['count', 'sum']\n",
    "    dest_state_agg['dest_state_delay_ratio'] = dest_state_agg['sum'] / dest_state_agg['count']\n",
    "    dest_state_agg = dest_state_agg['dest_state_delay_ratio'].reset_index()\n",
    "    \n",
    "    # 항공사 agg 연산\n",
    "    airline_grp = df.groupby('Airline')\n",
    "    airline_dict = {\n",
    "        'Airline' : ['count'],\n",
    "        'Delay' : ['sum']\n",
    "    }\n",
    "    airline_agg = airline_grp.agg(airline_dict)\n",
    "    airline_agg.columns = ['count', 'sum']\n",
    "    airline_agg['airline_delay_ratio'] = airline_agg['sum'] / airline_agg['count']\n",
    "    airline_agg = airline_agg['airline_delay_ratio'].reset_index()\n",
    "    \n",
    "    # Carrier_Code(IATA) agg 연산\n",
    "    carrier_grp = df.groupby('Carrier_Code(IATA)')\n",
    "    carrier_dict = {\n",
    "        'Carrier_Code(IATA)' : ['count'],\n",
    "        'Delay' : ['sum']\n",
    "    }\n",
    "    carrier_agg = carrier_grp.agg(carrier_dict)\n",
    "    carrier_agg.columns = ['count', 'sum']\n",
    "    carrier_agg['carrier_delay_ratio'] = carrier_agg['sum'] / carrier_agg['count']\n",
    "    carrier_agg = carrier_agg['carrier_delay_ratio'].reset_index()\n",
    "    \n",
    "    # 항공기 agg 연산\n",
    "    tail_grp = df.groupby('Tail_Number')\n",
    "    tail_dict = {\n",
    "        'Tail_Number' : ['count'],\n",
    "        'Delay' : ['sum']\n",
    "    }\n",
    "    tail_agg = tail_grp.agg(tail_dict)\n",
    "    tail_agg.columns = ['count', 'sum']\n",
    "    tail_agg['tail_delay_ratio'] = tail_agg['sum'] / tail_agg['count']\n",
    "    tail_agg = tail_agg['tail_delay_ratio'].reset_index()\n",
    "    \n",
    "    # df와 merge\n",
    "    df = df.merge(month_agg, on='Month', how='left')\n",
    "    df = df.merge(day_agg, on='Day_of_Month', how='left')\n",
    "    df = df.merge(depart_hour_agg, on='Estimated_Departure_Time_Hour', how='left')\n",
    "    df = df.merge(arrival_hour_agg, on='Estimated_Arrival_Time_Hour', how='left')\n",
    "    df = df.merge(origin_airport_agg, on='Origin_Airport', how='left')\n",
    "    df = df.merge(origin_state_agg, on='Origin_State', how='left')\n",
    "    df = df.merge(dest_airport_agg, on='Destination_Airport', how='left')\n",
    "    df = df.merge(dest_state_agg, on='Destination_State', how='left')\n",
    "    df = df.merge(airline_agg, on='Airline', how='left')\n",
    "    df = df.merge(carrier_agg, on='Carrier_Code(IATA)', how='left')\n",
    "    df = df.merge(tail_agg, on='Tail_Number', how='left')\n",
    "    \n",
    "    # 카테고리 컬럼 라벨링\n",
    "    object_columns = ['Origin_Airport', 'Origin_State', 'Destination_Airport',\n",
    "                     'Destination_State', 'Airline', 'Carrier_Code(IATA)', \n",
    "                     'Tail_Number']\n",
    "    for column in object_columns : \n",
    "        df[column] = pd.factorize(df[column])[0]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88282278",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# 학습 / 예측 / 평가 함수\n",
    "def lgbm_fit_eval(df) :\n",
    "    X = df.drop(['ID', 'Delay'], axis=1)\n",
    "    y = df['Delay']\n",
    "        \n",
    "    # 학습 데이터에 오버 샘플링 적용\n",
    "    randomOS = RandomOverSampler(random_state=2020)\n",
    "    X_over, y_over = randomOS.fit_resample(X, y)\n",
    "    train_X, valid_X, train_y, valid_y = train_test_split(X_over, y_over, test_size=0.3, random_state=2020, stratify=y_over)\n",
    "\n",
    "    lgbm = LGBMClassifier(n_jobs=-1, n_estimators=4000,\n",
    "                     learning_rate=0.02, silent=-1, verbose=-1,\n",
    "                         max_depth=13, max_bin=41, min_child_weight=3,\n",
    "                         num_leaves=60, reg_alpha=6.532, reg_lambda=2.818)\n",
    "\n",
    "    lgbm.fit(train_X, train_y, eval_set=[(train_X, train_y), (valid_X, valid_y)],\n",
    "            eval_metric='logloss', verbose=100, early_stopping_rounds=200)\n",
    "    return lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "944312fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000000, 19), (1000000, 18))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_test, df_sub = load_data()\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84bcab82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1255001, 16)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = preprocess_data(df_train, df_test)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "660b36c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1255001, 27)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_merge_agg(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c80b1547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000000, 27), (255001, 27))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train, test 분할\n",
    "df_test = df[df['Delay'].isnull()]\n",
    "df_train = df[df['Delay'].notnull()]\n",
    "\n",
    "df_test.shape, df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f77198",
   "metadata": {},
   "source": [
    "## OOF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc6296a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "def train_oof(df_train, df_test, nfolds=5) :\n",
    "    X = df_train.drop(['ID', 'Delay'], axis=1)\n",
    "    y = df_train['Delay']\n",
    "   \n",
    "    randomOS = RandomOverSampler(random_state=2020)\n",
    "    X_over, y_over = randomOS.fit_resample(X, y)\n",
    "    \n",
    "    folds = KFold(n_splits=nfolds, shuffle=True, random_state=2020)\n",
    "    \n",
    "    oof_preds = np.zeros((X_over.shape[0],2))\n",
    "    test_preds = np.zeros((df_test.shape[0],2))\n",
    "    \n",
    "    lgbm = LGBMClassifier(\n",
    "        n_jobs=-1, n_estimators=4000,\n",
    "        learning_rate=0.02, silent=-1, verbose=-1,\n",
    "        max_depth=13, max_bin=41, min_child_weight=3,\n",
    "        num_leaves=60, reg_alpha=6.532, reg_lambda=2.818\n",
    "    )\n",
    "    \n",
    "    for fold_idx, (train_idx, valid_idx) in enumerate(folds.split(X_over)) :\n",
    "        print('##### iteration ', fold_idx, ' 시작')\n",
    "        train_X  = X_over.iloc[train_idx, :]\n",
    "        train_y = y_over.iloc[train_idx]\n",
    "        valid_X = X_over.iloc[valid_idx, :]\n",
    "        valid_y = y_over.iloc[valid_idx]\n",
    "        \n",
    "        lgbm.fit(train_X, train_y, eval_set=[(train_X, train_y), (valid_X, valid_y)],\n",
    "                eval_metric='logloss', verbose=200, early_stopping_rounds=200)\n",
    "        \n",
    "        oof_preds[valid_idx] = lgbm.predict_proba(valid_X, num_iteration=lgbm.best_iteration_) \n",
    "        test_preds += lgbm.predict_proba(df_test.drop(['ID', 'Delay'], axis=1), num_iteration=lgbm.best_iteration_) / folds.n_splits\n",
    "    \n",
    "    return lgbm, test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d51165",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm, test_preds = train_oof(df_train, df_test, nfolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2859101",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('sample_submission.csv')\n",
    "submit[['Not_Delayed', 'Delayed']] = test_preds\n",
    "submit.to_csv('submission_v5.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
